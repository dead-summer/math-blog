#import "/typ/templates/blog.typ": *
#show: main.with(
  title: "PINN综述",
  author: "summer",
  desc: [PINN这些年的发展],
  date: "2025-12-23",
  tags: (
    blog-tags.machine-learning,
    blog-tags.pde,
  ),
  show-outline: true,
)

= 历史渊源

将神经网络用于求解微分方程的想法可追溯至上世纪 90 年代。@dissanayake1994neural 采用浅层网络配合数值梯度近似 PDE，使用配点法和拟牛顿优化求解。@lagaris1998ann 提出"试探函数 + 神经网络参数化"的框架，研究了规则与不规则边界条件下的边值问题。然而，受限于当时的硬件条件和优化算法，这些早期工作并未引起广泛关注。

= PINN 的核心技术与演进

物理信息神经网络（Physics-Informed Neural Networks, PINN）是一种将物理定律编码到神经网络中的科学机器学习方法。其核心思想是将求解微分方程转化为优化问题：训练神经网络逼近方程的解，损失函数由两部分构成——对已知数据（初始/边界条件）的拟合项，以及在时空域配点上强制满足物理方程的残差项。

现代 PINN 框架由 @raissi2019pinn 于 2017—2019 年正式确立。其成功的关键在于*自动微分（Automatic Differentiation, AD）*技术的引入，使得复杂 PDE 残差能够高效地集成到损失函数中，从而极大推动了该领域的发展。

同一时期，其他学者也提出了基于神经网络万能逼近性质求解 PDE 的方法。@e2018deepritz 提出 Deep Ritz 方法，通过最小化能量泛函求解边值问题；@sirignano2018dgm 提出 DGM 方法，采用 Galerkin 式残差最小化。这些方法——PINN（配点式）、Deep Ritz（能量式）、DGM（Galerkin 式）——共同构成了"科学机器学习"方法家族。

PINN 的发展并非单一模型的线性演进，而是一棵不断分枝的"家族树"。其演化主要沿两个方向展开：*物理信息的融入方式*与*神经网络架构的选择*。

== 基于物理信息融入方式的变体

标准 PINN 通过损失函数中的惩罚项"软约束"边界与初始条件，这需要精心调节各项权重。针对这一问题，研究者提出了不同的物理信息融入策略。

*硬约束方法*直接在网络结构中编码边界条件。PCNN @zhu2019pcnn @sun2019pcnn @liu2021dualdimer 通过特殊设计的网络结构，使输出在数学上*自动满足*边界/初始条件，损失函数仅包含物理残差项。这避免了权重调节的难题，但需要针对不同边界条件设计相应的网络结构。

*变分形式方法*从另一角度改进损失函数的构造。@kharazmi2020hpvpinn 提出 hp-VPINN，结合域分解（h-refinement）与子域内近似阶数调整（p-refinement）。该方法不直接最小化 PDE 残差的点误差，而是最小化其*变分形式或能量泛函*。通过分部积分，可*降低对解的导数阶数要求*（如二阶 PDE 的损失函数仅需一阶导数），从而提升训练稳定性。

*守恒型方法*专注于保持物理守恒性质。@jagtap2020cpinn 提出 cPINN（Conservative PINN），将计算域分解为多个子域，每个子域由独立的 PINN 求解，并在*子域交界面强制通量连续性*，确保整体解在离散意义上守恒。这种分解策略也天然支持并行计算。

== 基于神经网络架构的变体

@raissi2019pinn 最初采用*多层感知机（MLP）*作为 PINN 的基础架构。随着研究深入，学者们探索了多种神经网络结构以适应不同类型的问题。

=== 前馈网络变体

在保持前馈网络（Feed-forward Neural Network）结构的前提下，研究者尝试了不同的网络设计。@dwivedi2019pielm 将 PINN 与*极限学习机（ELM）*结合，提出 PI-ELM。ELM 的输入层权重随机初始化后固定不变，仅训练输出层权重，因此收敛速度极快。@amuthan2021spinn 提出 SPINN，采用*径向基函数（RBF）*等核函数代替部分全连接层，在减少参数量的同时提供一定的可解释性。

*算子学习*代表了另一个重要方向——不再学习单个 PDE 的解，而是学习从输入函数到输出函数的映射。@lu2021deeponet 提出 DeepONet，由 *Branch Net*（编码输入函数）和 *Trunk Net*（编码输出坐标）两个子网络构成。@cai2021deepmmnet 将其扩展为 DeepM\&Mnet，用于处理多物理场与多尺度耦合问题。

=== 卷积与循环架构

针对具有特殊结构的问题，研究者引入了 CNN 和 RNN 架构。@gao2020phygeonet 提出 PhyGeoNet，通过坐标变换将不规则物理域映射到规则计算域，从而发挥 CNN 在结构化网格上的优势。@wang2021tgae 提出 TgAE，采用编码器-解码器结构对高维随机场进行非线性降维，同时融入物理约束。

对于动态系统，RNN 的序列处理能力尤为适用。@viana2021pirnn 设计了物理信息 RNN，其单元结构直接模仿数值积分格式（如欧拉法、龙格-库塔法），将物理模型硬编码到网络中。@zhang2020pimlmlstm 提出 PhyLSTM，使用多个 LSTM 分别建模状态变量与非线性恢复力，通过张量微分器实现物理耦合。

=== 概率与集成架构

为实现不确定性量化，@yang2021bpinn 提出 B-PINN，采用*贝叶斯神经网络（BNN）*作为骨干。网络权重被建模为概率分布，通过后验采样（如 HMC 或变分推断）不仅给出预测值，还能量化预测的不确定性。

生成模型也被引入 PINN 框架。@liu2020pigan 提出 PI-GAN，利用 GAN 框架求解随机微分方程：生成器产生符合物理定律的解场，判别器评估其真实性，物理约束通过自动微分嵌入生成器。@stiller2020gatedpinn 提出 GatedPINN，采用*专家混合（Mixture-of-Experts）*架构，由门控网络动态选择或组合多个专家 PINN，实现对复杂问题域的自适应处理。



#bibliography("/assets/reference/pinn-review.bib")
